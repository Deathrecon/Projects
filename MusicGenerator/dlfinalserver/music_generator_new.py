import pickle
import numpy as np
from music21 import instrument, note, chord, stream
from tensorflow import keras

def load_data(composer):
    path = './model/'+composer+'/Data/'
    file1 = open(path+'notes.txt', 'r')
    notes = file1.readlines()

    for i in range(0,len(notes)):
        notes[i] = notes[i].strip('\n')

    file2 = open(path+'lengths.txt', 'r')
    lengths = file2.readlines()

    for i in range(0,len(lengths)):
        lengths[i] = lengths[i].strip('\n')

    with open(path+"networknotes.pkl", 'rb') as pickle_file:
        network_notes = pickle.load(pickle_file)

    with open(path+"networklength.pkl", 'rb') as pickle_file:
        network_lengths = pickle.load(pickle_file)

    return notes, lengths, network_notes, network_lengths

def run_midi(composer):
    notes,lengths,network_notes,network_lengths = load_data(composer)
    n_vocab = len(set(item for item in notes))
    l_vocab = len(set(item for item in lengths))
    pitchnames = sorted(set(item for item in notes))
    pitchlengths = sorted(set(item for item in lengths))
    model_notes = keras.models.load_model('./model/'+composer+'/note_model')
    model_lengths = keras.models.load_model('./model/'+composer+'/length_model')

    start = np.random.randint(0, len(network_notes)-1)
    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))
    int_to_len = dict((number, note) for number, note in enumerate(pitchlengths))
    pattern_note = network_notes[start]
    pattern_len = network_lengths[start]
    prediction_output_note = []
    prediction_output_len = []
    # generate 500 notes
    for note_index in range(500):
        prediction_input_note = np.reshape(pattern_note, (1, len(pattern_note), 1))
        prediction_input_note = prediction_input_note / float(n_vocab)
        prediction_input_len = np.reshape(pattern_len, (1, len(pattern_len), 1))

        prediction_note = model_notes.predict(prediction_input_note, verbose=0)
        prediction_len = model_lengths.predict(prediction_input_len, verbose=0)

        index_note = np.argmax(prediction_note)
        index_len = np.argmax(prediction_len)

        result_note = int_to_note[index_note]
        result_len = int_to_len[index_len]

        prediction_output_note.append(result_note)
        prediction_output_len.append(result_len)

        pattern_note = np.append(pattern_note, index_note)
        pattern_note = pattern_note[1:len(pattern_note)]
        pattern_len = np.append(pattern_len, index_len)
        pattern_len = pattern_len[1:len(pattern_len)]

    offset = 0
    output_notes = []
    # create note and chord objects based on the values generated by the model
    for i in range(0,len(prediction_output_note)):
        pattern_note = prediction_output_note[i]
        # pattern is a chord
        if ('.' in pattern_note) or pattern_note.isdigit():
            notes_in_chord = pattern_note.split('.')
            notes = []
            for current_note in notes_in_chord:
                new_note = note.Note(int(current_note))
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
            new_chord = chord.Chord(notes)
            new_chord.offset = offset

            if "/" in prediction_output_len[i]:
                split = prediction_output_len[i].split("/")
                new_chord.quarterLength = float(int(split[0])/int(split[1]))
            else:
                new_chord.quarterLength = float(prediction_output_len[i])
            output_notes.append(new_chord)
        # pattern is a note
        else:
            new_note = note.Note(pattern_note)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()

            if "/" in prediction_output_len[i]:
                split = prediction_output_len[i].split("/")
                new_note.quarterLength = float(int(split[0])/int(split[1]))
            else:
                new_note.quarterLength = float(prediction_output_len[i])

            output_notes.append(new_note)
        # increase offset each iteration so that notes do not stack
        offset += 0.5

    midi_stream = stream.Stream(output_notes)
    midi_stream.write('midi', fp='./output.midi')